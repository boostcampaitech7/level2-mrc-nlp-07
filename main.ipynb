{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import & Dataset 읽어오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import concatenate_datasets, load_from_disk\n",
    "from src.retriever.retrieval.sparse_retrieval import SparseRetrieval\n",
    "from transformers import AutoTokenizer\n",
    "from src.utils.constants import column_names\n",
    "\n",
    "org_dataset = load_from_disk('data/train_dataset')\n",
    "print(org_dataset)\n",
    "full_ds = concatenate_datasets(\n",
    "        [\n",
    "            org_dataset[column_names.TRAIN].flatten_indices(),\n",
    "            org_dataset[column_names.VALIDATION].flatten_indices(),\n",
    "        ]\n",
    "    )  # train dev 를 합친 4192 개 질문에 대해 모두 테스트\n",
    "print(\"*\" * 40, \"query dataset\", \"*\" * 40)\n",
    "print(full_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retriever 선언 및 Retriever 진행\n",
    "* 아마 초기엔 학습 진행하는데 시간 좀 걸릴예정\n",
    "    * 약 15분정도 소요(승범 컴 기준)\n",
    "    * 노션에 mrc/검증결과/Sparse 처리에 가장 좋은 bm25올려났으므로 그거 data 폴더 안에 넣으면 실행가능."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위에서 선언한거 가져오기 Retriever\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-multilingual-cased\", use_fast=False,)\n",
    "retriever = SparseRetrieval(\n",
    "    tokenize_fn=tokenizer.tokenize,\n",
    "    data_path=\"./data/\",\n",
    "    context_path=\"wikipedia_documents.json\",\n",
    "    mode = \"bm25\",\n",
    "    max_feature=1000000,\n",
    "    ngram_range=(1,2),\n",
    "    #tokenized_docs = tokenized_docs,\n",
    ")\n",
    "retriever.get_sparse_embedding()\n",
    "\n",
    "# Top k 조절.\n",
    "df = retriever.retrieve(full_ds, topk=10)\n",
    "\n",
    "# 여기서 df가 reader가 사용할 데이터 프레임입니다.\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* question : 질문\n",
    "* id : mrc 번호\n",
    "* retrieval_context : retrieval 결과로 나온 topk를 하나의 text로 만든것\n",
    "* original_context : 실제 retrieval 정답\n",
    "* answers: dict 형태\n",
    "    * answers_start : original_context에서 어디에서 시작하는지\n",
    "    * text: 정답의 text값이 뭔지 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[column_names.RETRIEVAL_CONTEXT][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retriever 결과물 DatasetDict로 저장\n",
    "reader는 데이터셋을 DatasetDict형태로 받으므로, df에서 변환이 필요하다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "# df를 Dataset으로\n",
    "retriever_dataset = Dataset.from_pandas(df)\n",
    "\n",
    "# DatasetDict로 변환 (train과 validation을 동일 데이터로 초기화)\n",
    "dataset_dict = DatasetDict({\n",
    "    column_names.TRAIN: retriever_dataset,\n",
    "    column_names.VALIDATION: retriever_dataset\n",
    "})\n",
    "\n",
    "# train 스플릿: 'original_context'를 'context'로 사용\n",
    "dataset_dict[column_names.TRAIN] = dataset_dict[column_names.TRAIN]\\\n",
    "    .remove_columns([column_names.RETRIEVAL_CONTEXT])\\\n",
    "    .rename_column(column_names.ORIGINAL_CONTEXT, column_names.CONTEXT)\n",
    "\n",
    "# validation 스플릿: 'retrieval_context'를 'context'로 사용\n",
    "dataset_dict[column_names.VALIDATION] = dataset_dict[column_names.VALIDATION]\\\n",
    "    .remove_columns([column_names.ORIGINAL_CONTEXT])\\\n",
    "    .rename_column(column_names.RETRIEVAL_CONTEXT, column_names.CONTEXT)\n",
    "\n",
    "print(dataset_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 별도 파일로 저장\n",
    "dataset_dict.save_to_disk('outputs/bm25')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['Unnamed: 0', 'question', 'id', 'retrieval_context'],\n",
      "        num_rows: 600\n",
      "    })\n",
      "})\n",
      "DatasetDict({\n",
      "    validation: Dataset({\n",
      "        features: ['question', 'id', 'context'],\n",
      "        num_rows: 600\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# csv파일을 읽어오기\n",
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "# 스플릿을 validation으로 읽기 %csv 하나만 읽으면 'train' 스플릿으로 읽으니 주의\n",
    "retriever_dataset = load_dataset('csv', data_files='data/test.csv')\n",
    "\n",
    "# 불러온 Dataset 확인\n",
    "print(retriever_dataset)\n",
    "\n",
    "# train을 validation으로 변경\n",
    "dataset_dict = DatasetDict({\n",
    "    column_names.VALIDATION: retriever_dataset[column_names.TRAIN]\n",
    "})\n",
    "\n",
    "# validation 스플릿: 'retrieval_context'를 'context'로 사용\n",
    "dataset_dict[column_names.VALIDATION] = dataset_dict[column_names.VALIDATION].remove_columns(\n",
    "    column_names.UNNAMED\n",
    "    ).rename_column(\n",
    "        column_names.RETRIEVAL_CONTEXT, column_names.CONTEXT)\n",
    "\n",
    "print(dataset_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': '대통령을 포함한 미국의 행정부 견제권을 갖는 국가 기관은?', 'id': 'mrc-1-000067', 'context': '[\\'미국 상의원 또는 미국 상원(United States Senate)은 양원제인 미국 의회의 상원이다.\\\\\\\\n\\\\\\\\n미국 부통령이 상원의장이 된다. 각 주당 2명의 상원의원이 선출되어 100명의 상원의원으로 구성되어 있다. 임기는 6년이며, 2년마다 50개주 중 1/3씩 상원의원을 새로 선출하여 연방에 보낸다.\\\\\\\\n\\\\\\\\n미국 상원은 미국 하원과는 다르게 미국 대통령을 수반으로 하는 미국 연방 행정부에 각종 동의를 하는 기관이다. 하원이 세금과 경제에 대한 권한, 대통령을 포함한 대다수의 공무원을 파면할 권한을 갖고 있는 국민을 대표하는 기관인 반면 상원은 미국의 주를 대표한다. 즉 캘리포니아주, 일리노이주 같이 주 정부와 주 의회를 대표하는 기관이다. 그로 인하여 군대의 파병, 관료의 임명에 대한 동의, 외국 조약에 대한 승인 등 신속을 요하는 권한은 모두 상원에게만 있다. 그리고 하원에 대한 견제 역할(하원의 법안을 거부할 권한 등)을 담당한다. 2년의 임기로 인하여 급진적일 수밖에 없는 하원은 지나치게 급진적인 법안을 만들기 쉽다. 대표적인 예로 건강보험 개혁 당시 하원이 미국 연방 행정부에게 퍼블릭 옵션(공공건강보험기관)의 조항이 있는 반면 상원의 경우 하원안이 지나치게 세금이 많이 든다는 이유로 퍼블릭 옵션 조항을 제외하고 비영리건강보험기관이나 보험회사가 담당하도록 한 것이다. 이 경우처럼 상원은 하원이나 내각책임제가 빠지기 쉬운 국가들의 국회처럼 걸핏하면 발생하는 의회의 비정상적인 사태를 방지하는 기관이다. 상원은 급박한 처리사항의 경우가 아니면 법안을 먼저 내는 경우가 드물고 하원이 만든 법안을 수정하여 다시 하원에 되돌려보낸다. 이러한 방식으로 단원제가 빠지기 쉬운 함정을 미리 방지하는 것이다.날짜=2017-02-05\\', \\'국회에 관해 규정하는 헌법 제4장의 첫 조문이다.\\\\n\\\\n본조에서 말하는 \"국권\"이란 국가가 갖는 지배권을 포괄적으로 나타내는 국가 권력, 곧 국가의 통치권을 의미한다. 국권은 일반적으로 입법권·행정권·사법권의 3권으로 분류되지만, 그 중에서도 주권자인 국민의 의사를 직접 반영하는 기관으로서 국회를 \"최고 기관\"으로 규정한 것이다. 다만, 최고 기관이라 해서 타 기관의 감시와 통제를 받지 않는 것은 아니며 권력 분립 원칙에 따라 국회에 대한 행정권, 사법권의 견제를 받는다.\\\\n\\\\n또한 일본 전체 국민을 대표하는 기관을 국회로 규정함으로써, 국회는 일본의 유일한 입법 기관의 지위를 가지고 있다. 일본 제국 헌법 하에서 입법권은 천황의 권한에 속했으며, 제국의회는 천황의 입법 행위를 보좌하는 기관에 불과했다.\\\\n\\\\n여기서 \"유일한 입법 기관\"의 의미로는 다음과 같은 해석이 있다.\\\\n* 국회 중심 입법 원칙 : 국회가 국가의 입법권을 독점한다는 원칙\\\\n* 국회 단독 입법 원칙 : 국회의 입법은 다른 기관의 간섭 없이 이루어진다는 원칙\\\\n\\\\n또한 국회의 입법에 벗어나지 않는 범위 내에서 행정 기관은 정령 등의 규칙 제정권을 가지며(헌법 제73조 제6호), 최고재판소는 소송에 관한 절차, 변호사 및 재판소에 관한 내부 규율 및 사법 사무 처리에 관한 사항에 대한 규칙 제정권(헌법 제77조 제1항)을 가진다.\\', \\'내각(內閣, cabinet)은 행정부의 주요 각료들로 구성되는 국가의 주요기관이다.\\\\n\\\\n의원내각제에서 내각은 수상과 여러 장관으로 조직되는 합의체로, 국가의 행정권을 담당하고 국회에 대한 연대책임을 갖는다. 의원내각제에 있어서 내각은 국가행정의 최고기관인 한편 국민이 구성시키는 의회에 의하여 철저히 견제되어 의회민주주의 체제를 이룬다.\\\\n\\\\n그 직접적 유래는 영국에서 국왕의 정치를 자문하던 추밀원에서 찾을 수 있다. 특히 내각은 추밀원의 일개 회의에서 시작하였다가 권한이 집중되어 분리된 기관으로, 이후 국왕의 실권이 사라지고 일명 웨스트민스터 시스템으로 불리는 의원내각제가 성립하면서 의회에 의한 민주적 행정부를 이루게 되었다.\\\\n\\\\n한편 국가원수에게 대부분의 권력이 집중되는 대통령중심제와 군주제에서 내각은 원칙적으로 의결권이 없거나 의결의 구속력이 없는 보좌기관에 불과한 경우가 많다.(예: 대한민국의 국무회의)\\\\n\\\\n대한민국은 국무회의가 내각에 속하며 권한이 대통령에 비해 제한적이다. 과거 왕조시대 때는 고려시대의 중서문하성, 중추원, 육부 또는 조선시대의 의정부와 육조가 내각과 비슷한 성향을 지니고 있었다.\\', \\'이하의 국가들은 의회에서 행정부 수반을 선출한다는 점에서 내각제와 닮았다. 그리고 이들 국가들 중 상당수는 행정부 수반이 의회해산권을 갖고, 의회는 내각불신임권을 갖는데 이점 역시 내각제와 닮았다. 하지만 내각제와 달리 의회에서 선출되는 자는 행정부 수반의 지위 뿐만 아니라 국가 원수의 지위도 가진다. 그래서 의회에서 선출되는 자의 직위는 총리가 아니라, 대통령이다. 이처럼 1인이 행정부 수반과 국가 원수의 지위를 겸한다는 점에서 대통령중심제와 닮았다. 이상과 같은 이유로 이들 국가들의 정부 형태는 대통령제와 내각제의 절충형이지만, 행정 권한이 2인에게로 분리되어 있지 않으므로 이원집정부제는 아니다.\\\\n\\\\n \\\\n* 나우루\\\\n* 남아프리카 공화국\\\\n* 마셜 제도\\\\n* 마카오\\\\n* 미얀마\\\\n* 미크로네시아 연방\\\\n* 보츠와나\\\\n* 산마리노\\\\n* 수리남\\\\n* 키리바시\\\\n* 홍콩\\', \"미국의 외교정책의 수립과 이행에 대한 주된 책임을 대통령이 지게 되어 있으나, 의회도 이에 대해 강한 통제력을 발휘할 수 있다. 우선 의회는 전쟁을 선포할 수 있는 권한이 있다. 하원은 대통령의 외교정책 수행에 필요한 예산에 대해 강한 통제력을 가지고 있으며, 상원도 재원에 대한 통제가 가능하다. 특히 상원의 경우에는 고급 외무 관리의 임명에 대한 통제력을 가지고 있을 뿐만 아니라, 미국이 체결하는 모든 조약에 대한 비준권을 가지고 있다. 의회의 이와 같은 제재 권한은 행정부와 의회의 갈등을 초래하는 요소로 작용한다. 에드워드 코르윈(Edward Samuel Corwin) 교수는 미국의 정치체계가 외교정책에 있어서 행정부와 의회 간의 투쟁을 초래한다고 지적한 바 있다. 그 좋은 예로서는 상원이 국제연맹 헌장의 비준을 거부한 사실을 들 수 있다. 의회와 행정부간에는 긴밀한 협조가 이루어지고 있다. 유엔헌장 비준 당시의 의회와 행정부 간의 긴밀한 협조는 너무나 유명하다. 그러나 이러한 협동외교는 한국에서 흔히 사용되고 있는 \\'초당외교\\'라는 말과는 엄격히 구분되어야 한다. 베트남 전쟁으로 말미암아 파생된 행정부와 의회 간의 갈등은 심각한 형편이었다. 그러나 의회가 대통령에 가하는 압력은 행정부의 독주를 견제하는 동시에 건전한 방향의 미국 대외정책을 모색하고 있다. 의회는 국민의 대표기구로서 국민의 의사와 직결돼 있다. 따라서 대외정책의 수립이나 이행 과정에도 항상 의회를 \\'문제아\\'로 취급하거나, 또는 그러한 범주 내에 의회의 기능을 이해해서는 안 된다.\", \\'직권남용죄(職權濫用罪)는 공무원이 직권을 남용하여 사람으로 하여금 의무 없는 일을 행하게 하거나 사람의 권리행사를 방해하는 죄이다. 5년 이하의 징역과 10년 이하의 자격정지 또는 1천만원 이하의 벌금에 처한다(대한민국 형법 제123조). 공무원이 그 직권을 남용하여 국가 또는 지방자치단체 작용의 엄정(嚴正)을 해하였다는 데에 본죄의 특질이 있으며 헌법적으로 주권자인 국민에 대해 봉사자인 공무원이 갑질하는 것을 예방하여 국민주권주의를 기본으로 하는 헌정질서 수호를 목적으로 한다. 하지만 오랜 비민주적인 통치 권력이 집권하던 시기에 공무원에 의한 전횡적인 횡포가 잇따르자 1988년 6월 항쟁의 결실로 대통령 선거 직선제 등 민주화 개헌을 하면서 행정부 견제 수단으로 헌법재판소를 신설하면서 국민이 헌법재판소에 직접 \\\\\\'공권력 행사나 불행사에 의한 기본권 침해가 있은 때\\\\\\'에 헌법소원을 청구할 수 있게 하였는데 그 대상이 직권남용과 직무유기 범죄가 되는 내용이다.\\\\n\\\\n\\\\\\'직권의 남용\\\\\\'이란 형식적으로 일반직무권한에 속하는 사항에 대하여 자기의 직권을 남용하여 행사하는 것을 말한다. 의무없는 일을 하게 하거나 권리행사를 방해하는 것으로서 예컨대 부당하게 과중한 세금을 부과하여 납부케 하는 경우도 포함한다. 공무원이 직권을 남용하여 폭행·협박으로써 사람의 권리행사를 방해한 경우에는 본죄가 아니라 324조의 죄를 구성하며 그 처벌은 135조의 규정에 의하여 그 형의 2분의 1까지 가중한다. \\\\n\\\\n그러나 현실적으로 적용하여 처벌하는 것은 거의 없다. 특히 범죄 구성요건으로 \"강제성이 있어야 한다\"고 하는데 마치 하여야 하는 것 처럼 지시하고선 추후에 강제성이 없어 직권남용이 아니라고 하는 것은 모순이 있고 무엇보다 검사의 독점적 기소 권한의 폐단 성격이 짙으며 사회적인 화제가 될 때 기소가 이루어진다.\\', \\'리히텐슈타인의 의회주의는 1862년 헌법과 함께 시작되었다고 할 수 있다. 이렇게 생긴 의회는 대부분이 국민의 자유선거로 선출되어 국민을 대표하는 최초의 의회였다. 의원정수는 15명으로 줄었다. 그 중 3명은 제후가 임명하고, 나머지 12명은 국민이 간접선거를 통해 선출했다. 선거를 위해 우선 지역공동체에서 남성 100인당 2인의 선거인단을 선출하고, 선거인단 총회에서 의원을 선출했다. 의회는 국가기능에 영향을 미치는 가장 중요한 기관은 아니었지만, 가장 중요한 기관들 중에 하나가 되었다. 의회는 국제조약과 세금인상법의 입법에 영향력을 행사했고, 행정기관을 견제하고 징병법안에 동의할 수 있는 권한을 가지게 되었다.\\', \"통일주체국민회의는 1972년 10월 17일 10월 유신으로 제4공화국이 출범하면서 헌법에 따라 구성된 간접민주주의 기관이다. 가장 중요한 기능은 유신헌법의 핵심인 대통령의 간접 선거 기능을 담당한 것이다. 1973년 8월부터 약칭은 국민회의로 정해졌다. 국민회의는 전국의 각 지역구에서 국민의 직접 선거로 선출된 대의원들로 구성되었는데, 통일주체국민회의 대의원들은 비공식적으로 통대라는 약칭으로 불리었다.\\\\n\\\\n유신헌법 제3장에 의하면 통일주체국민회의는 국가의 정상기관(頂上機關)이자 주권적 수임 기관으로서, 조국의 평화적 통일을 촉진하기 위한 국민의 총의가 모인 곳이다. 따라서 6년의 임기를 가진 이 기관의 대의원은 국민의 직접선거로 선출되며, 대통령을 선출하고 국회의원 정수의 3분의 1(유신정우회)을 선출하며, 국회의 헌법 개정안을 최종 의결하고 통일 정책을 심의하는 기능을 갖고 있다.\\\\n\\\\n신민당은 제9대 대통령 선거를 앞두고 정당이 대통령 후보를 지명하고, 대의원 선거에 출마하는 대의원 후보들은 지지하는 대통령 후보를 정하고 선거를 치르게 하는 미국의 대통령 선거인 선거 방식의 통일주체국민회의 대의원 선거법 개정안을 내기도 하였으나 이루어지지 않았다. \\\\n\\\\n사실상  박정희 대통령의 거수기 노릇을 하던 이 기관은 1979년 10월 26일 그가 암살되자 그 후임 대통령인 최규하와 전두환을 형식적으로 선출해주는 역할을 맡은 뒤, 이듬해 제5공화국 헌법 발효와 함께 해체되었다. 그 후 대통령간선제를 담당하는 기관은 대통령 선거인단으로 교체되었으며, 사무처와 인적구성 및 대통령 직속 통일 관련 기구로써의 역할은 \\'평화통일정책자문회의\\'를 거쳐 민주평화통일자문회의로 이어지고 있다.\", \"통일주체국민회의는 1972년 10월 17일 10월 유신으로 제4공화국이 출범하면서 헌법에 따라 구성된 간접민주주의 기관이다. 가장 중요한 기능은 유신헌법의 핵심인 대통령의 간접 선거 기능을 담당한 것이다. 1973년 8월부터 약칭은 국민회의로 정해졌다. 국민회의는 전국의 각 지역구에서 국민의 직접 선거로 선출된 대의원들로 구성되었는데, 통일주체국민회의 대의원들은 비공식적으로 통대라는 약칭으로 불리었다.\\\\\\\\n\\\\\\\\n유신헌법 제3장에 의하면 통일주체국민회의는 국가의 정상기관(頂上機關)이자 주권적 수임 기관으로서, 조국의 평화적 통일을 촉진하기 위한 국민의 총의가 모인 곳이다. 따라서 6년의 임기를 가진 이 기관의 대의원은 국민의 직접선거로 선출되며, 대통령을 선출하고 국회의원 정수의 3분의 1(유신정우회)을 선출하며, 국회의 헌법 개정안을 최종 의결하고 통일 정책을 심의하는 기능을 갖고 있다.\\\\\\\\n\\\\\\\\n신민당은 제9대 대통령 선거를 앞두고 정당이 대통령 후보를 지명하고, 대의원 선거에 출마하는 대의원 후보들은 지지하는 대통령 후보를 정하고 선거를 치르게 하는 미국의 대통령 선거인 선거 방식의 통일주체국민회의 대의원 선거법 개정안을 내기도 하였으나 이루어지지 않았다. \\\\\\\\n\\\\\\\\n사실상 박정희 대통령의 거수기 노릇을 하던 이 기관은 1979년 10월 26일 그가 암살되자 그 후임 대통령인 최규하와 전두환을 형식적으로 선출해주는 역할을 맡은 뒤, 이듬해 제5공화국 헌법 발효와 함께 해체되었다. 그 후 대통령간선제를 담당하는 기관은 대통령 선거인단으로 교체되었으며, 사무처와 인적구성 및 대통령 직속 통일 관련 기구로써의 역할은 \\'평화통일정책자문회의\\'를 거쳐 민주평화통일자문회의로 이어지고 있다.\", \"1957년 말부터 1958년 초에 걸쳐 미국 국가항공자문위원회 (NACA)는 그때까지 자신들이 한 일과 같은 역할을 맡은 비군사적 기관의 신설에 대한 검토를 시작했다. 또 그 개념을 정밀 조사하기 위해서 몇 개의 위원회를 창설했다. 1958년 1월 12일, NACA는 가이포드 스테버(Guyford Stever)를 의장으로 하는 \\'우주 기술 특별 위원회\\' 를 설립했다. 이 위원회는, 제2차 세계 대전 후에 미국 시민권을 획득한 베르너 폰 브라운 박사를 리더로 하는 미국 육군 탄도 미사일국의 우주 로켓 개발 그룹에서 제안된, 거대 로켓 개발 계획을 자문하는 임무도 띠고 있었다.\\\\n\\\\n1958년 1월 14일, NACA 책임자 휴 드라이덴은 \\'우주 기술을 위한 국가적 조사 계획\\'을 발표해, 이하와 같이 말했다.\\\\n\\\\n미국의 위신 및 군사적 필요성의 양면에서 생각하면, 이번 도전(스푸트니크)에 휩쓸린 우주 정복을 위한 조사 및 개발의 계획을 정력적으로 추진하는 것은 긴급하고 중요한 과제이다.(중략) 그 때문에, 비군사적인 국가 기관에 의해서 과학적인 조사를 해야 한다는 제안이 이루어졌다.(중략) NACA는 우주 개발 기술의 주도권을 취해 그 성과를 급속히 확대해 연장할 수 있는 능력이 있다.\\\\n\\\\n1958년 1월 31일 오후 10시 48분 (미국 동부표준시), 미국 첫 인공위성인 익스플로러 1호가 발사되었다. 1958년 3월 5일, 대통령 직속 과학 기술 자문 위원회의 위원장 제임스 킬리안(James Killian)은 아이젠하워 대통령에게 「민간 우주 계획을 위한 조직」이라는 제목의 서신을 보내, 일정의 지연을 최소한으로 억제해 조사 계획을 확장할 수 있도록 NACA를 강화해 재편한 조직에 의한 문민 통제형의 우주 계획을 창립하는 것을 재촉했다. 동년 3월 말에 NACA는, 당시 기획 중이었던 수소와 불소를 추진제로 하는 100만 파운드(453톤, 445만 뉴턴)의 추진력을 가지는 3단 로켓의 개발 계획을 포함한, 「우주 개발에 관한 제의」라는 제목의 보고서를 발표했다.\\\\n\\\\n동년 4월, 아이젠하워 대통령은 의회 연설을 통해, 민간 주도의 우주 개발 기관을 신설할 의향과 미국 항공우주국 설립을 위한 예산안을 설명했다. NACA의 조사 활동 하나를 봐도, 그 규모나 진전, 관리, 운영 등에 있어서 변화가 이루어져야 했다. 7월 16일, 의회는 예산안을 승인하고, 동시에 NASA 설립을 위한 구체적인 근거가 된 \\'국가 항공 우주 결의\\'에 대해서도 약간의 언급을 했다. 그 이틀 후, 베르너 폰 브라운이 인솔하는 작업 그룹은 예비 보고서를 제출해, 현재 미국의 우주 개발은 여러 가지 기관이 따로 시행하고 있어 상호 제휴가 결핍되어 국가적 노력이 중복되어 손해가 크다는 것을 강력하게 비판했다. 스테버의 우주 개발 위원회는 브라운의 비판에 동의해, 10월에는 최종적인 초안이 제출되었다.\"]', 'answers': {'answer_start': [235], 'text': ['하원']}}\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "# CSV 파일에서 데이터 로드\n",
    "train_retriever_dataset = load_dataset('csv', data_files='data/train.csv')\n",
    "\n",
    "# DatasetDict로 train과 validation을 정의\n",
    "train_dataset_dict = DatasetDict({\n",
    "    column_names.TRAIN: train_retriever_dataset[column_names.TRAIN]  # 'train' 스플릿으로 지정\n",
    "})\n",
    "\n",
    "# 불필요한 컬럼 제거 및 'retrieval_context'를 'context'로 변경\n",
    "train_dataset_dict[column_names.TRAIN] = train_dataset_dict[column_names.TRAIN]\\\n",
    "    .remove_columns(column_names.REMOVE_COLUMNS_FROM_RETRIEVER)\\\n",
    "    .rename_column(column_names.RETRIEVAL_CONTEXT, column_names.CONTEXT)\n",
    "\n",
    "# 'answers' 필드를 파싱하여 딕셔너리로 변환하는 함수\n",
    "def process_answers(example):\n",
    "    # 'answers' 필드가 문자열로 저장된 경우 이를 딕셔너리로 변환\n",
    "    if isinstance(example[column_names.ANSWER], str):\n",
    "        example[column_names.ANSWER] = ast.literal_eval(example[column_names.ANSWER])\n",
    "    return example\n",
    "\n",
    "# 'answers' 필드를 처리하여 파싱\n",
    "train_dataset_dict[column_names.TRAIN] = train_dataset_dict[column_names.TRAIN]\\\n",
    "    .map(process_answers)\n",
    "\n",
    "# 'train' 데이터셋의 첫 번째 예시 출력\n",
    "print(train_dataset_dict[column_names.TRAIN][0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## do train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForQuestionAnswering were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-processing...\n",
      "preprocessed Dataset({\n",
      "    features: ['input_ids', 'attention_mask', 'start_positions', 'end_positions'],\n",
      "    num_rows: 99096\n",
      "})\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='115' max='12388' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  115/12388 00:38 < 1:09:49, 2.93 it/s, Epoch 0.02/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 27\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Reader 모델 학습 실행\u001b[39;00m\n\u001b[1;32m     26\u001b[0m reader_model \u001b[38;5;241m=\u001b[39m Reader(model_args, data_args, training_args, dataset)\n\u001b[0;32m---> 27\u001b[0m \u001b[43mreader_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/level2-mrc-nlp-07/src/reader/model/reader.py:74\u001b[0m, in \u001b[0;36mReader.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     67\u001b[0m trainer \u001b[38;5;241m=\u001b[39m trainer_manager\u001b[38;5;241m.\u001b[39mcreate_trainer(\n\u001b[1;32m     68\u001b[0m     train_dataset\u001b[38;5;241m=\u001b[39mtrain_dataset, eval_dataset\u001b[38;5;241m=\u001b[39meval_dataset, eval_example\u001b[38;5;241m=\u001b[39mdata_handler\u001b[38;5;241m.\u001b[39mplain_data(\n\u001b[1;32m     69\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalidation\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     70\u001b[0m     ) \u001b[38;5;28;01mif\u001b[39;00m training_args\u001b[38;5;241m.\u001b[39mdo_eval \u001b[38;5;129;01mor\u001b[39;00m training_args\u001b[38;5;241m.\u001b[39mdo_predict \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, post_processing_function\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_handler\u001b[38;5;241m.\u001b[39mprocess_func(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpos\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m     71\u001b[0m )\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training_args\u001b[38;5;241m.\u001b[39mdo_train:\n\u001b[0;32m---> 74\u001b[0m     train_result \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresult_saver\u001b[38;5;241m.\u001b[39msave_results(trainer, train_result, train_dataset, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training_args\u001b[38;5;241m.\u001b[39mdo_eval:\n",
      "File \u001b[0;32m~/level2-mrc-nlp-07/src/reader/model/trainer_manager.py:94\u001b[0m, in \u001b[0;36mTrainerManager.run_training\u001b[0;34m(self, trainer, train_dataset)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;124;03m모델 학습을 실행합니다.\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;124;03m    Any: 학습 결과.\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     93\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_args\u001b[38;5;241m.\u001b[39mresume_from_checkpoint \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 94\u001b[0m train_result \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheckpoint\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m train_result\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:2052\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2050\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2051\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2052\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2053\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2054\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2055\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2056\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2057\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:2388\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2385\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   2387\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 2388\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2390\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2391\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2392\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2393\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2394\u001b[0m ):\n\u001b[1;32m   2395\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2396\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:3518\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3516\u001b[0m         scaled_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m   3517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3518\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3520\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mdetach() \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mgradient_accumulation_steps\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:2246\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   2244\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlomo_backward(loss, learning_rate)\n\u001b[1;32m   2245\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2246\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from transformers import HfArgumentParser, TrainingArguments\n",
    "from datasets import DatasetDict\n",
    "from src.reader.model.reader import Reader\n",
    "from src.utils.arguments import DataTrainingArguments, ModelArguments\n",
    "\n",
    "# Argument 설정\n",
    "model_args = ModelArguments()\n",
    "data_args = DataTrainingArguments()\n",
    "training_args = TrainingArguments(output_dir='outputs/models/train_dataset')\n",
    "\n",
    "# 학습 관련 설정\n",
    "training_args.do_train = True\n",
    "training_args.do_eval = False\n",
    "training_args.do_predict = False\n",
    "\n",
    "# 학습 하이퍼파라미터 설정\n",
    "model_args.model_name_or_path = 'klue/bert-base'  # 학습에 사용할 모델\n",
    "training_args.learning_rate = 5e-5  # 학습률\n",
    "training_args.num_train_epochs = 1  # epoch 수\n",
    "training_args.per_device_train_batch_size = 16  # 학습 배치 사이즈\n",
    "\n",
    "# 데이터셋 로드 (BM25 기반으로 생성된 데이터셋)\n",
    "dataset = train_dataset_dict\n",
    "\n",
    "# Reader 모델 학습 실행\n",
    "reader_model = Reader(model_args, data_args, training_args, dataset)\n",
    "reader_model.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## do eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Argument 설정\n",
    "model_args = ModelArguments()\n",
    "data_args = DataTrainingArguments()\n",
    "training_args = TrainingArguments(output_dir='outputs/train_dataset')\n",
    "\n",
    "# 평가 관련 설정\n",
    "training_args.do_train = False\n",
    "training_args.do_eval = True\n",
    "training_args.do_predict = False\n",
    "\n",
    "# 학습된 모델 경로 설정\n",
    "model_args.model_name_or_path = 'outputs/models/train_dataset'\n",
    "\n",
    "# 평가 데이터셋 로드 (BM25 기반으로 생성된 데이터셋)\n",
    "dataset = DatasetDict.load_from_disk('outputs/bm25')\n",
    "\n",
    "# Reader 모델 평가 실행\n",
    "reader_model = Reader(model_args, data_args, training_args, dataset)\n",
    "reader_model.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## do predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Argument 설정\n",
    "model_args = ModelArguments()\n",
    "data_args = DataTrainingArguments()\n",
    "training_args = TrainingArguments(output_dir='outputs/test_dataset')\n",
    "\n",
    "# 추론 관련 설정\n",
    "training_args.do_train = False\n",
    "training_args.do_eval = False\n",
    "training_args.do_predict = True\n",
    "\n",
    "# 학습된 모델 경로 및 테스트 데이터셋 경로 설정\n",
    "model_args.model_name_or_path = 'outputs/models/train_dataset'\n",
    "data_args.dataset_name = 'data/test_dataset'  # 추론에 사용할 테스트 데이터셋 경로\n",
    "\n",
    "# 테스트 데이터셋 로드\n",
    "dataset = dataset_dict\n",
    "\n",
    "# Reader 모델 추론 실행\n",
    "reader_model = Reader(model_args, data_args, training_args, dataset)\n",
    "reader_model.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('outputs/test_dataset/predictions.json', 'r', encoding='utf-8') as f:\n",
    "    input_json = json.load(f)\n",
    "\n",
    "# 변환된 데이터 저장을 위한 빈 딕셔너리\n",
    "output_dict = {}\n",
    "\n",
    "# 입력 JSON을 순회하면서 변환\n",
    "for item in input_json:\n",
    "    output_dict[item[column_names.ID]] = item[column_names.PREDICTION_TEST]\n",
    "\n",
    "# 결과 출력\n",
    "print(output_dict)\n",
    "\n",
    "with open('outputs/test_dataset/converted_data.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(output_dict, f, ensure_ascii=False, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mrc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
