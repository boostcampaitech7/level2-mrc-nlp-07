{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import & Dataset 읽어오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['title', 'context', 'question', 'id', 'answers', 'document_id', '__index_level_0__'],\n",
      "        num_rows: 3952\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['title', 'context', 'question', 'id', 'answers', 'document_id', '__index_level_0__'],\n",
      "        num_rows: 240\n",
      "    })\n",
      "})\n",
      "**************************************** query dataset ****************************************\n",
      "Dataset({\n",
      "    features: ['title', 'context', 'question', 'id', 'answers', 'document_id', '__index_level_0__'],\n",
      "    num_rows: 4192\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import concatenate_datasets, load_from_disk\n",
    "from src.retriever.retrieval.sparse_retrieval import SparseRetrieval\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "org_dataset = load_from_disk('data/train_dataset')\n",
    "print(org_dataset)\n",
    "full_ds = concatenate_datasets(\n",
    "        [\n",
    "            org_dataset[\"train\"].flatten_indices(),\n",
    "            org_dataset[\"validation\"].flatten_indices(),\n",
    "        ]\n",
    "    )  # train dev 를 합친 4192 개 질문에 대해 모두 테스트\n",
    "print(\"*\" * 40, \"query dataset\", \"*\" * 40)\n",
    "print(full_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retriever 선언 및 Retriever 진행\n",
    "* 아마 초기엔 학습 진행하는데 시간 좀 걸릴예정\n",
    "    * 약 15분정도 소요(승범 컴 기준)\n",
    "    * 노션에 mrc/검증결과/Sparse 처리에 가장 좋은 bm25올려났으므로 그거 data 폴더 안에 넣으면 실행가능."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lengths of unique contexts : 56737\n",
      "Building bm25 embedding...\n",
      "Start Initializing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenizing...: 100%|██████████| 56737/56737 [02:22<00:00, 399.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating n-grams and building vocabulary...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating n-grams: 100%|██████████| 56737/56737 [00:35<00:00, 1604.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current mode : bm25\n",
      "End Initialization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating BM25: 100%|██████████| 57/57 [23:33<00:00, 24.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish BM25 Embedding\n",
      "bm25 embedding shape: (56737, 1000000)\n",
      "(4192, 1000000) (56737, 1000000)\n",
      "<class 'scipy.sparse._csr.csr_matrix'> <class 'scipy.sparse._csr.csr_matrix'>\n",
      "result shape : (4192, 56737)\n",
      "[query exhaustive search] done in 58.911 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e2f62fa81a24ea4be5f48ecab1780bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sparse retrieval:   0%|          | 0/4192 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>id</th>\n",
       "      <th>retrieval_context</th>\n",
       "      <th>original_context</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>대통령을 포함한 미국의 행정부 견제권을 갖는 국가 기관은?</td>\n",
       "      <td>mrc-1-000067</td>\n",
       "      <td>이하의 국가들은 의회에서 행정부 수반을 선출한다는 점에서 내각제와 닮았다. 그리고 ...</td>\n",
       "      <td>미국 상의원 또는 미국 상원(United States Senate)은 양원제인 미국...</td>\n",
       "      <td>{'answer_start': [235], 'text': ['하원']}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>현대적 인사조직관리의 시발점이 된 책은?</td>\n",
       "      <td>mrc-0-004397</td>\n",
       "      <td>'근대적 경영학' 또는 '고전적 경영학'에서 현대적 경영학으로 전환되는 시기는 19...</td>\n",
       "      <td>'근대적 경영학' 또는 '고전적 경영학'에서 현대적 경영학으로 전환되는 시기는 19...</td>\n",
       "      <td>{'answer_start': [212], 'text': ['《경영의 실제》']}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>강희제가 1717년에 쓴 글은 누구를 위해 쓰여졌는가?</td>\n",
       "      <td>mrc-1-000362</td>\n",
       "      <td>1943년 초, 마리아 발토르타가 9년 간 건강 상태가 안 좋아졌을 때, 그녀의 고...</td>\n",
       "      <td>강희제는 강화된 황권으로 거의 황제 중심의 독단적으로 나라를 이끌어 갔기에 자칫 전...</td>\n",
       "      <td>{'answer_start': [510], 'text': ['백성']}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11~12세기에 제작된 본존불은 보통 어떤 나라의 특징이 전파되었나요?</td>\n",
       "      <td>mrc-0-001510</td>\n",
       "      <td>이 불상군은 1978년 발견되어 학계에 알려졌으며 봉황리 햇골산 중턱 두 곳에 약간...</td>\n",
       "      <td>불상을 모시기 위해 나무나 돌, 쇠 등을 깎아 일반적인 건축물보다 작은 규모로 만든...</td>\n",
       "      <td>{'answer_start': [625], 'text': ['중국']}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>명문이 적힌 유물을 구성하는 그릇의 총 개수는?</td>\n",
       "      <td>mrc-0-000823</td>\n",
       "      <td>양산 통도사의 금동천문도의 전면에는 천구(天球)의 북극을 중심으로 둥글게 북극으로 ...</td>\n",
       "      <td>동아대학교박물관에서 소장하고 있는 계사명 사리구는 총 4개의 용기로 구성된 조선후기...</td>\n",
       "      <td>{'answer_start': [30], 'text': ['4개']}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  question            id  \\\n",
       "0         대통령을 포함한 미국의 행정부 견제권을 갖는 국가 기관은?  mrc-1-000067   \n",
       "1                   현대적 인사조직관리의 시발점이 된 책은?  mrc-0-004397   \n",
       "2           강희제가 1717년에 쓴 글은 누구를 위해 쓰여졌는가?  mrc-1-000362   \n",
       "3  11~12세기에 제작된 본존불은 보통 어떤 나라의 특징이 전파되었나요?  mrc-0-001510   \n",
       "4               명문이 적힌 유물을 구성하는 그릇의 총 개수는?  mrc-0-000823   \n",
       "\n",
       "                                   retrieval_context  \\\n",
       "0  이하의 국가들은 의회에서 행정부 수반을 선출한다는 점에서 내각제와 닮았다. 그리고 ...   \n",
       "1  '근대적 경영학' 또는 '고전적 경영학'에서 현대적 경영학으로 전환되는 시기는 19...   \n",
       "2  1943년 초, 마리아 발토르타가 9년 간 건강 상태가 안 좋아졌을 때, 그녀의 고...   \n",
       "3  이 불상군은 1978년 발견되어 학계에 알려졌으며 봉황리 햇골산 중턱 두 곳에 약간...   \n",
       "4  양산 통도사의 금동천문도의 전면에는 천구(天球)의 북극을 중심으로 둥글게 북극으로 ...   \n",
       "\n",
       "                                    original_context  \\\n",
       "0  미국 상의원 또는 미국 상원(United States Senate)은 양원제인 미국...   \n",
       "1  '근대적 경영학' 또는 '고전적 경영학'에서 현대적 경영학으로 전환되는 시기는 19...   \n",
       "2  강희제는 강화된 황권으로 거의 황제 중심의 독단적으로 나라를 이끌어 갔기에 자칫 전...   \n",
       "3  불상을 모시기 위해 나무나 돌, 쇠 등을 깎아 일반적인 건축물보다 작은 규모로 만든...   \n",
       "4  동아대학교박물관에서 소장하고 있는 계사명 사리구는 총 4개의 용기로 구성된 조선후기...   \n",
       "\n",
       "                                         answers  \n",
       "0        {'answer_start': [235], 'text': ['하원']}  \n",
       "1  {'answer_start': [212], 'text': ['《경영의 실제》']}  \n",
       "2        {'answer_start': [510], 'text': ['백성']}  \n",
       "3        {'answer_start': [625], 'text': ['중국']}  \n",
       "4         {'answer_start': [30], 'text': ['4개']}  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 위에서 선언한거 가져오기 Retriever\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-multilingual-cased\", use_fast=False,)\n",
    "retriever = SparseRetrieval(\n",
    "    tokenize_fn=tokenizer.tokenize,\n",
    "    data_path=\"./data/\",\n",
    "    context_path=\"wikipedia_documents.json\",\n",
    "    mode = \"bm25\",\n",
    "    max_feature=1000000,\n",
    "    ngram_range=(1,2),\n",
    "    #tokenized_docs = tokenized_docs,\n",
    ")\n",
    "retriever.get_sparse_embedding()\n",
    "\n",
    "# Top k 조절.\n",
    "df = retriever.retrieve(full_ds, topk=10)\n",
    "\n",
    "# 여기서 df가 reader가 사용할 데이터 프레임입니다.\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* question : 질문\n",
    "* id : mrc 번호\n",
    "* retrieval_context : retrieval 결과로 나온 topk를 하나의 text로 만든것\n",
    "* original_context : 실제 retrieval 정답\n",
    "* answers: dict 형태\n",
    "    * answers_start : original_context에서 어디에서 시작하는지\n",
    "    * text: 정답의 text값이 뭔지 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13059"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['retrieval_context'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retriever 결과물 DatasetDict로 저장\n",
    "reader는 데이터셋을 DatasetDict형태로 받으므로, df에서 변환이 필요하다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['question', 'id', 'context', 'answers'],\n",
      "        num_rows: 4192\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['question', 'id', 'context', 'answers'],\n",
      "        num_rows: 4192\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "# df를 Dataset으로\n",
    "retriever_dataset = Dataset.from_pandas(df)\n",
    "\n",
    "# DatasetDict로 변환 (train과 validation을 동일 데이터로 초기화)\n",
    "dataset_dict = DatasetDict({\n",
    "    'train': retriever_dataset,\n",
    "    'validation': retriever_dataset\n",
    "})\n",
    "\n",
    "# train 스플릿: 'original_context'를 'context'로 사용\n",
    "dataset_dict['train'] = dataset_dict['train'].remove_columns(['retrieval_context']).rename_column('original_context', 'context')\n",
    "\n",
    "# validation 스플릿: 'retrieval_context'를 'context'로 사용\n",
    "dataset_dict['validation'] = dataset_dict['validation'].remove_columns(['original_context']).rename_column('retrieval_context', 'context')\n",
    "\n",
    "print(dataset_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac2969b576364bb89400c73af2b966cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/4192 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "640a222a481b4345a48a0d0ef10d949c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/4192 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 별도 파일로 저장\n",
    "dataset_dict.save_to_disk('outputs/bm25')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['Unnamed: 0', 'question', 'id', 'retrieval_context'],\n",
      "        num_rows: 600\n",
      "    })\n",
      "})\n",
      "DatasetDict({\n",
      "    validation: Dataset({\n",
      "        features: ['question', 'id', 'context'],\n",
      "        num_rows: 600\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# csv파일을 읽어오기\n",
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "# 스플릿을 validation으로 읽기 %csv 하나만 읽으면 'train' 스플릿으로 읽으니 주의\n",
    "retriever_dataset = load_dataset('csv', data_files='data/test (1).csv')\n",
    "\n",
    "# 불러온 Dataset 확인\n",
    "print(retriever_dataset)\n",
    "\n",
    "# train을 validation으로 변경\n",
    "dataset_dict = DatasetDict({\n",
    "    'validation': retriever_dataset['train']\n",
    "})\n",
    "\n",
    "# validation 스플릿: 'retrieval_context'를 'context'로 사용\n",
    "dataset_dict['validation'] = dataset_dict['validation'].remove_columns('Unnamed: 0').rename_column('retrieval_context', 'context')\n",
    "\n",
    "print(dataset_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output directory: outputs\n",
      "DatasetDict({\n",
      "    validation: Dataset({\n",
      "        features: ['question', 'id', 'context'],\n",
      "        num_rows: 600\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-processing...\n",
      "['question', 'id', 'context']\n",
      "Dataset({\n",
      "    features: ['question', 'id', 'context'],\n",
      "    num_rows: 600\n",
      "})\n",
      "preprocessed Dataset({\n",
      "    features: ['input_ids', 'token_type_ids', 'attention_mask', 'offset_mapping', 'example_id'],\n",
      "    num_rows: 14401\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/trainer_pt_utils.py:483: FutureWarning: DistributedTensorGatherer is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1801' max='1801' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1801/1801 01:50]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "postprocess_qa Dataset({\n",
      "    features: ['question', 'id', 'context'],\n",
      "    num_rows: 600\n",
      "})\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf8a75cdf21a45bbaed738d9039c477f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-24 02:49:43,242 - postprocess log - INFO - Saving predictions to outputs/predictions.json.\n",
      "2024-10-24 02:49:43,244 - postprocess log - INFO - Saving nbest_preds to outputs/nbest_predictions.json.\n",
      "2024-10-24 02:49:43,397 - outputs - INFO - Predictions saved to outputs/predictions.json\n"
     ]
    }
   ],
   "source": [
    "from transformers import HfArgumentParser\n",
    "from transformers import TrainingArguments\n",
    "from datasets import DatasetDict\n",
    "\n",
    "from src.reader.model.reader import Reader\n",
    "from src.utils.arguments import DataTrainingArguments, ModelArguments\n",
    "\n",
    "#args 로드\n",
    "model_args = ModelArguments()\n",
    "data_args =  DataTrainingArguments()\n",
    "training_args = TrainingArguments(output_dir='outputs')\n",
    "\n",
    "# 세부 세팅\n",
    "# model_args.model_name_or_path = <모델경로/huggingface>\n",
    "model_args.model_name_or_path = 'outputs'\n",
    "\n",
    "\n",
    "#training_args.do_train =True\n",
    "#training_args.do_eval = True\n",
    "training_args.do_predict =True\n",
    "# 디스크로 데이터셋 불러오기\n",
    "#dataset = DatasetDict.load_from_disk('data/train_dataset')\n",
    "\n",
    "#데이터셋 바로 받아올 경우\n",
    "dataset = dataset_dict\n",
    "\n",
    "\n",
    "# output_dir은 training_args에 설정된 값을 사용\n",
    "print(\"Output directory:\", training_args.output_dir)\n",
    "print(dataset)\n",
    "\n",
    "\n",
    "reader_model = Reader(model_args, data_args, training_args, dataset)\n",
    "reader_model.run()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "level2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
