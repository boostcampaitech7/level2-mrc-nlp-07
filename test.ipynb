{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\C4022\\Desktop\\study\\coding\\naver_boot\\level2-mrc-nlp-07\\level2\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['title', 'context', 'question', 'id', 'answers', 'document_id', '__index_level_0__'],\n",
      "        num_rows: 3952\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['title', 'context', 'question', 'id', 'answers', 'document_id', '__index_level_0__'],\n",
      "        num_rows: 240\n",
      "    })\n",
      "})\n",
      "**************************************** query dataset ****************************************\n",
      "Dataset({\n",
      "    features: ['title', 'context', 'question', 'id', 'answers', 'document_id', '__index_level_0__'],\n",
      "    num_rows: 4192\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import concatenate_datasets, load_from_disk\n",
    "from src.retrieval.retrieval import SparseRetrieval\n",
    "from transformers import AutoTokenizer\n",
    "from src.score.ranking import check_original_in_context, calculate_reverse_rank_score, calculate_linear_score\n",
    "org_dataset = load_from_disk('./data/train_dataset')\n",
    "print(org_dataset)\n",
    "full_ds = concatenate_datasets(\n",
    "        [\n",
    "            org_dataset[\"train\"].flatten_indices(),\n",
    "            org_dataset[\"validation\"].flatten_indices(),\n",
    "        ]\n",
    "    )  # train dev 를 합친 4192 개 질문에 대해 모두 테스트\n",
    "print(\"*\" * 40, \"query dataset\", \"*\" * 40)\n",
    "print(full_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lengths of unique contexts : 56737\n",
      "Building tfidf embedding...\n",
      "Start Initializing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenizing...: 100%|██████████| 56737/56737 [01:59<00:00, 473.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Vocab\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "빌딩 어휘: 100%|██████████| 56737/56737 [00:01<00:00, 50522.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculate doc frequency\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "문서 빈도 계산: 100%|██████████| 56737/56737 [00:02<00:00, 20456.05it/s]\n",
      "c:\\Users\\C4022\\Desktop\\study\\coding\\naver_boot\\level2-mrc-nlp-07\\level2\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current mode : tfidf\n",
      "End Initialization\n",
      "Finish Sklearn TF-IDF Embedding\n",
      "New embeddings calculated and saved.\n",
      "tfidf embedding shape: (56737, 50000)\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-multilingual-cased\", use_fast=False,)\n",
    "    # 위에서 선언한거 가져오기 Retriever\n",
    "retriever = SparseRetrieval(\n",
    "    tokenize_fn=tokenizer.tokenize,\n",
    "    data_path=\"./data/\",\n",
    "    context_path=\"wikipedia_documents.json\",\n",
    "    mode = \"tfidf\",\n",
    ")\n",
    "retriever.get_sparse_embedding()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4192, 50000) (56737, 50000)\n",
      "result shape : (4192, 56737)\n",
      "[query exhaustive search] done in 28.676 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sparse retrieval: 100%|██████████| 4192/4192 [00:01<00:00, 3929.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct retrieval 0.6063931297709924\n",
      "reverse rank retrieval 0.23666993470962353\n",
      "linear retrieval 0.4822570194053708\n"
     ]
    }
   ],
   "source": [
    "df = retriever.retrieve(full_ds, topk=10)\n",
    "df[\"correct\"] = df.apply(check_original_in_context, axis=1)\n",
    "df[\"rmm_score\"] = df.apply(calculate_reverse_rank_score, axis=1)\n",
    "df[\"linear_score\"] = df.apply(calculate_linear_score, axis=1)\n",
    "print(\n",
    "    \"correct retrieval\",\n",
    "    df[\"correct\"].sum() / len(df),\n",
    ")\n",
    "print(\n",
    "    \"reverse rank retrieval\",\n",
    "    df[\"rmm_score\"].sum() / len(df)\n",
    ")\n",
    "print(\n",
    "    \"linear retrieval\",\n",
    "    df[\"linear_score\"].sum() / len(df)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse._csr.csr_matrix'> (1, 46680)\n",
      "(4192, 46680) <class 'scipy.sparse._csr.csr_matrix'>\n",
      "유사도 계산\n",
      "(4192, 46680) (56737, 46680)\n",
      "유사도 후\n",
      "result shape : (4192, 56737)\n",
      "[query exhaustive search] done in 21.866 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sparse retrieval: 100%|██████████| 4192/4192 [00:00<00:00, 9681.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct retrieval result by fiass search 0.35854007633587787\n",
      "mrr retrieval result by fiass search 0.35854007633587787\n",
      "linear retrieval result by fiass search 0.35854007633587787\n"
     ]
    }
   ],
   "source": [
    "df = retriever.retrieve(full_ds, topk=1)\n",
    "df[\"correct\"] = df.apply(check_original_in_context, axis=1)\n",
    "df[\"rmm_score\"] = df.apply(calculate_reverse_rank_score, axis=1)\n",
    "df[\"linear_score\"] = df.apply(calculate_linear_score, axis=1)\n",
    "print(\n",
    "    \"correct retrieval result by fiass search\",\n",
    "    df[\"correct\"].sum() / len(df),\n",
    ")\n",
    "print(\n",
    "    \"mrr retrieval result by fiass search\",\n",
    "    df[\"rmm_score\"].sum() / len(df)\n",
    ")\n",
    "print(\n",
    "    \"linear retrieval result by fiass search\",\n",
    "    df[\"linear_score\"].sum() / len(df)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"correct\"] = df.apply(check_original_in_context, axis=1)\n",
    "df[\"rmm_score\"] = df.apply(calculate_reverse_rank_score, axis=1)\n",
    "df[\"linear_score\"] = df.apply(calculate_linear_score, axis=1)\n",
    "print(\n",
    "    \"correct retrieval result by fiass search\",\n",
    "    df[\"correct\"].sum() / len(df),\n",
    ")\n",
    "print(\n",
    "    \"mrr retrieval result by fiass search\",\n",
    "    df[\"rmm_score\"].sum() / len(df)\n",
    ")\n",
    "print(\n",
    "    \"linear retrieval result by fiass search\",\n",
    "    df[\"linear_score\"].sum() / len(df)\n",
    ")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "level2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
