{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 이상치 분석 자동화 실험"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 필요한 모듈 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langchain-ollama=0.2.0\n",
    "%pip install langchain=0.3.4\n",
    "%pip install matplotlib=3.9.2\n",
    "%pip install numpy=1.26.4\n",
    "%pip install pandas=2.2.3\n",
    "%pip install pyarrow=17.0.0\n",
    "%pip install seaborn=0.13.2\n",
    "%pip install sentencepiece=0.2.0\n",
    "%pip install transformers=4.45.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema import StrOutputParser\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '../data/train_dataset/train/dataset.arrow'\n",
    "with pa.memory_map(file_path, 'r') as source:\n",
    "    table = pa.ipc.open_stream(source).read_all()\n",
    "df: pd.DataFrame = table.to_pandas()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_column = 'context'  # 예: 'context', 'document' 등\n",
    "if text_column not in df.columns:\n",
    "    print(f\"Warning: '{text_column}' column not found. Please specify the correct column name.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\* 로컬 Ollama 서버로 llama2 활용하는 방법 (macOS 기준)\n",
    "1. Ollama 설치\n",
    "    ```bash\n",
    "    brew install ollama\n",
    "    ```\n",
    "2. Ollama 서버 실행\n",
    "    ```bash\n",
    "    ollama run llama2\n",
    "    ```\n",
    "3. Ollama 서버 중단\n",
    "    ```bash\n",
    "    pkill ollama\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 로드 및 프롬프트 세팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OllamaLLM(model=\"llama2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-7b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tree of Thoughts 적용 프롬프트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_analysis_template = \"\"\"\n",
    "You are a Data Analyst. You are tasked with doing EDA for modeling Open-Domain Question Answering. You are tasked with analyzing the following text based on potential anomalies and preprocessing requirements. Use a Tree of Thoughts approach to evaluate multiple reasoning paths. Answer the following questions strictly with 'Yes' or 'No' where applicable, and provide concise reasoning or recommendations if an issue is detected.\n",
    "\n",
    "Context: {context},\n",
    "Question: {question},\n",
    "Answer: {answer}\n",
    "\n",
    "### Step 1: Anomaly Detection\n",
    "1. Does this text contain any structural, semantic, or formatting anomalies? (Yes/No)\n",
    "    - If 'Yes', explain the anomaly briefly.\n",
    "\n",
    "### Step 2: Special Character Evaluation\n",
    "2. Are there any unnecessary special characters or symbols in this text that do not contribute to the meaning? (Yes/No)\n",
    "    - If 'Yes', specify which characters should be removed or replaced.\n",
    "\n",
    "### Step 3: Preprocessing Requirements\n",
    "3. Does this text require any preprocessing to improve its structure or readability? (Yes/No)\n",
    "    - If 'Yes', specify the type of preprocessing required (e.g., punctuation removal, spacing correction, formatting adjustments).\n",
    "\n",
    "### Step 4: Sufficiency of Context\n",
    "4. Is the provided context sufficient and specific enough to answer the given question correctly? (Yes/No)\n",
    "    - If 'No', explain briefly why the context is inadequate.\n",
    "\n",
    "### Step 5: Logical Consistency\n",
    "5. Can a human logically infer the answer to the given question from the provided context? (Yes/No)\n",
    "    - If 'No', explain the logical defection briefly.\n",
    "\n",
    "Answer each question concisely based on your findings. Only answer with 'Yes' when you found ANY OUTLYING. Answer 'No' ONLY IF ALL CONDITIONS MATCH.\n",
    "\"\"\"\n",
    "\n",
    "text_analysis_prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\", \"answer\"],\n",
    "    template=text_analysis_template\n",
    ")\n",
    "\n",
    "text_analysis_chain = (\n",
    "    {\n",
    "        \"context\": RunnablePassthrough(),\n",
    "        \"question\": RunnablePassthrough(),\n",
    "        \"answer\": RunnablePassthrough(),\n",
    "    }\n",
    "    | text_analysis_prompt\n",
    "    | llm  # Executes the analysis through Llama2 or your chosen LLM\n",
    "    | StrOutputParser()  # Parses the result into a string format\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_TOKEN_LIMIT = 2048\n",
    "TEMPLATE_OVERHEAD = 150"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Llama2 입력 전 제어를 위한 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_input(context, question, answer, template_length=TEMPLATE_OVERHEAD):\n",
    "    \"\"\"\n",
    "    Ensures that the combined input stays within the token limit.\n",
    "    If the context is too long, it will be truncated to fit.\n",
    "    \"\"\"\n",
    "    # Tokenize the context, question, and answer using LlamaTokenizer\n",
    "    context_tokens = tokenizer.encode(context, add_special_tokens=False)\n",
    "    question_tokens = tokenizer.encode(question, add_special_tokens=False)\n",
    "    answer_tokens = tokenizer.encode(answer, add_special_tokens=False)\n",
    "\n",
    "    # Calculate how much space is left for the context after accounting for the question, answer, and template\n",
    "    available_tokens_for_context = MAX_TOKEN_LIMIT - (len(question_tokens) + len(answer_tokens) + template_length)\n",
    "\n",
    "    # If context exceeds the available space, truncate it\n",
    "    if len(context_tokens) > available_tokens_for_context:\n",
    "        # Truncate the context tokens\n",
    "        context_tokens = context_tokens[:available_tokens_for_context]\n",
    "\n",
    "    # Decode the truncated context back into text\n",
    "    trimmed_context = tokenizer.decode(context_tokens, clean_up_tokenization_spaces=True)\n",
    "    \n",
    "    return trimmed_context\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QA 데이터를 LLM에 입력하고 응답을 반환하는 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_qa_sample(context, question, answer):\n",
    "    # Trim the context if necessary\n",
    "    trimmed_context = trim_input(context, question, answer)\n",
    "\n",
    "    # Invoke the LLM analysis with the trimmed context\n",
    "    result = text_analysis_chain.invoke({\n",
    "        \"context\": trimmed_context,\n",
    "        \"question\": question,\n",
    "        \"answer\": answer\n",
    "    })\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = df.iloc[696][\"context\"]\n",
    "question = df.iloc[696][\"question\"]\n",
    "answer = df.iloc[696][\"answer\"]\n",
    "result_txt = process_qa_sample(context, question, answer)\n",
    "\n",
    "for i, c in enumerate(result_txt):\n",
    "    if i % 50 == 0:\n",
    "        print(f\"{c}\\n\")\n",
    "    else:\n",
    "        print(f\"{c}\", end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_special_chars(text):\n",
    "    # Detect special characters that are not common in ODQA data\n",
    "    special_chars = re.findall(r'[^\\w\\s\\.\\,\\!\\?\\\"\\'\\:\\;\\-\\(\\)\\[\\]\\{\\}]', text)\n",
    "    return list(set(special_chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터에서 결측치를 감지하는 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_simple_anomalies(text, question, answer):\n",
    "    \"\"\"Detects simple anomalies in text, question, or answer.\"\"\"\n",
    "    special_chars = analyze_special_chars(text)\n",
    "    is_text_missing = text is None or text.strip() == \"\"\n",
    "    is_question_missing = question is None or question.strip() == \"\"\n",
    "    is_answer_missing = answer is None or answer.strip() == \"\"\n",
    "\n",
    "    simple_anomalies = []\n",
    "\n",
    "    if special_chars:\n",
    "        simple_anomalies.append(f\"Special characters: {special_chars}\")\n",
    "    \n",
    "    if is_text_missing:\n",
    "        simple_anomalies.append(\"Missing or empty context.\")\n",
    "    if is_question_missing:\n",
    "        simple_anomalies.append(\"Missing or empty question.\")\n",
    "    if is_answer_missing:\n",
    "        simple_anomalies.append(\"Missing or empty answer.\")\n",
    "\n",
    "    return simple_anomalies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the sample size to either 100 or the size of the DataFrame, whichever is smaller\n",
    "sample_size = min(100, len(df))\n",
    "sample_indices = np.random.choice(len(df), sample_size, replace=False)\n",
    "\n",
    "# Open the file for writing the results\n",
    "with open('autoEDA.txt', 'w') as f:\n",
    "    for idx in sample_indices:\n",
    "        # Extract the text from the context column\n",
    "        text = df.iloc[idx]['context']\n",
    "        question = df.iloc[idx]['question']\n",
    "        answer = df.iloc[idx]['answers']['text'][0]  # Assuming first answer in list\n",
    "\n",
    "        # Detect simple anomalies\n",
    "        simple_anomalies = detect_simple_anomalies(text, question, answer)\n",
    "\n",
    "        # Run LLM analysis\n",
    "        result = text_analysis_chain.invoke(\n",
    "            {\n",
    "                \"context\": text,\n",
    "                \"question\": question,\n",
    "                \"answer\": answer,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # If any anomalies detected, write them to the file\n",
    "        if simple_anomalies or ('Yes' in result):\n",
    "            f.write(f\"Sample {idx}:\\n\")\n",
    "            f.write(f\"Context: {text[:100]}...\\n\" if len(text) > 100 else f\"Context: {text}\\n\")\n",
    "            f.write(f\"Question: {question}\\n\")\n",
    "            f.write(f\"Answer: {answer}\\n\")\n",
    "            \n",
    "            if simple_anomalies:\n",
    "                f.write(\"Simple Anomalies:\\n\")\n",
    "                f.write(\"\\n\".join(simple_anomalies) + \"\\n\")\n",
    "            \n",
    "            if 'Yes' in result:\n",
    "                f.write(\"LLM Analysis:\\n\")\n",
    "                f.write(f\"{result}\\n\")\n",
    "            \n",
    "            f.write(\"-\" * 50 + \"\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EDA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
